#!/usr/bin/python
from time import time 
from pytube import Playlist,YouTube
from concurrent.futures import as_completed, ThreadPoolExecutor
import sys

# rewrite it with asynio
# DONE: capped the number of workers to number of urls fetched

start=time()
def is_playlist(og_url):
    return True if (og_url.__contains__("list")) else False

def get_length(lnk):
   return int(YouTube(lnk).length)

def get_title(lnk):
    return YouTube(lnk).title
def print_fmt(ss):
    m,s = divmod(ss,60)
    h,m = divmod(m,60)
    print(f'{h:d}:{m:02d}:{s:02d}')
def get_playlist_urls(lnk):
    return Playlist(lnk).video_urls
    
arg_url=str(sys.argv[1])
if(not is_playlist(arg_url)):
    print(get_title(arg_url))
    print_fmt(get_length(arg_url))
    sys.exit("Done.")
print(f"link is a playlist")
urls_list=get_playlist_urls(arg_url)
num_workers=len(urls_list)
# prints urls of the playlist
#print("\n".join(urls_list))
# TODO: too many lists
threads=list()
threads_s=list()
titles=list()
time_s=list()
# TODO: figure out optimum number of threads
with ThreadPoolExecutor(max_workers=num_workers) as execc:
    for link in urls_list:
        threads.append(execc.submit(get_title,link))
for job in as_completed(threads):
    titles.append(job.result())
    #print(job.result())
# TODO: make a method for threading, you are repeating yourself, waiting for titles also is not good
#threads=list()
with ThreadPoolExecutor(max_workers=num_workers) as exexc:
    for link in urls_list:
        threads_s.append(exexc.submit(get_length,link))
for job in as_completed(threads_s):
    time_s.append(job.result())
print("Total Length: ",sep='',end='')
#print(" ".join(map(str,time_s)))
# Time is off by alot of seconds (divmod?)
print_fmt(sum(time_s))
print(f"Number of Videos:{len(urls_list)}")
print(f"Time to Execute: {time()-start}")
